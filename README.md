# Graph-Generative-Pretraining-Literature

Focus on 2D graph. 

## Survey

* [A Systematic Survey of Chemical Pre-trained Models](https://arxiv.org/pdf/2210.16484.pdf)

## Methods 

* [GPT-GNN](https://arxiv.org/pdf/2006.15437.pdf), Ziniu Hu, et al. 2020    
Single graph. Order sensitive. 

* [Strategies for Pretraining Graph Neural Networks](https://arxiv.org/pdf/1905.12265.pdf), Weihua Hu, et al. ICLR 2020

* [Pretraining via Denoising for Molecular Property Prediction](https://arxiv.org/pdf/2206.00133.pdf),  ICLR 2022.   
3D graph, but focusing on denoising diffusion for pretraining. 

* [Mole-Bert](https://openreview.net/pdf?id=jevY-DtiZTR)

* [GROVER](https://proceedings.neurips.cc/paper_files/paper/2020/file/94aef38441efa3380a3bed3faf1f9d5d-Paper.pdf)


## Study 

* [Does gnn pretraining help molecular representation?](https://arxiv.org/abs/2207.06010) Ruoxi Sun, et al. NeurIPS 2022



## Datasets 
* [Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets](https://openreview.net/forum?id=Zc2aIcucwc), Dominique Beaini, et al. 2024 ICLR

Need to find other interesting datasets, perhaps outside the molecular domain. 




## Most cited contrastive learning 



## Other self supervised learning 